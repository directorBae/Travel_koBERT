{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd6GYlveaZ-q"
      },
      "source": [
        "# SetUp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB9YGzP4Yb2P",
        "outputId": "c31b2a03-0cc5-4298-97f6-e74c7bc55aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.9/dist-packages (from mxnet) (1.22.4)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.9/dist-packages (from mxnet) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.12)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.5/344.5 KB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from gluonnlp) (1.22.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from gluonnlp) (0.29.33)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from gluonnlp) (23.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp39-cp39-linux_x86_64.whl size=680529 sha256=0008db30283a7d7b6971c8740871e5a1d9e69ec482f35dcb33a25cc7aa573b2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/17/70/b257bc53879a458c4bfcc900e89271aa8b4f19366a54bd2455\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==3.0.2\n",
            "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.0/769.0 KB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.9/dist-packages (from transformers==3.0.2) (0.1.97)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==3.0.2) (3.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==3.0.2) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from transformers==3.0.2) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==3.0.2) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from transformers==3.0.2) (1.22.4)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "  Downloading tokenizers-0.8.1rc1.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.4/97.4 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==3.0.2) (2022.10.31)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==3.0.2) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==3.0.2) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==3.0.2) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==3.0.2) (2.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==3.0.2) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==3.0.2) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers==3.0.2) (1.1.1)\n",
            "Building wheels for collected packages: tokenizers, sacremoses\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0m  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=bbcc2196a5f1503b2473190be4ce037e02714b14b3bc6b3486b4ee17528228d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "Successfully built sacremoses\n",
            "Failed to build tokenizers\n",
            "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3.0.2\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NcTd5A0YdVT",
        "outputId": "986fd28b-c8b7-4fa0-fcf4-5d28715545b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-yjcec8ft\n",
            "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-yjcec8ft\n",
            "  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3<=1.15.18\n",
            "  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from kobert==0.2.3) (0.10.0)\n",
            "Collecting mxnet<=1.7.0.post2,>=1.4.0\n",
            "  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n",
            "  Downloading onnxruntime-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n",
            "  Downloading sentencepiece-0.1.96-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n",
            "  Downloading torch-1.10.1-cp39-cp39-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n",
            "  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (23.3.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.22.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.19.6)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.19.0,>=1.18.18\n",
            "  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (23.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.33)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.9/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.27.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.5.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.65.0)\n",
            "Collecting sacremoses\n",
            "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.10.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.10.31)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.26,>=1.20\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.12.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.1.1)\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15705 sha256=52115f7fc9bdcb42b367c55c8a1d85170c3e66cf55d64fd794196efa133a8fe3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cxl6yy8h/wheels/0b/20/d8/031374f3d29b5150c59c814bed091fca7d6d4c8218148bf286\n",
            "Successfully built kobert\n",
            "Installing collected packages: tokenizers, sentencepiece, urllib3, torch, sacremoses, onnxruntime, jmespath, botocore, s3transfer, mxnet, huggingface-hub, transformers, boto3, kobert\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.97\n",
            "    Uninstalling sentencepiece-0.1.97:\n",
            "      Successfully uninstalled sentencepiece-0.1.97\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: mxnet\n",
            "    Found existing installation: mxnet 1.9.1\n",
            "    Uninstalling mxnet-1.9.1:\n",
            "      Successfully uninstalled mxnet-1.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.10.1 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.10.1 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boto3-1.15.18 botocore-1.18.18 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4totJpENpAmI",
        "outputId": "8b952e9a-e85e-4245-83ad-04450f3dec53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==3.6.0\n",
            "  Downloading gensim-3.6.0.tar.gz (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.9/dist-packages (from gensim==3.6.0) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.9/dist-packages (from gensim==3.6.0) (1.10.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from gensim==3.6.0) (1.16.0)\n",
            "Requirement already satisfied: smart_open>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from gensim==3.6.0) (6.3.0)\n",
            "Building wheels for collected packages: gensim\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-3.6.0-cp39-cp39-linux_x86_64.whl size=23915439 sha256=3dfcf82483854494f9b2cfc11f416c0bd82bd5ce55213dc1ba18f54254fadba7\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/12/f2/84de20fba5e870553796b0834d11109992f06ddc20aaead086\n",
            "Successfully built gensim\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.1\n",
            "    Uninstalling gensim-4.3.1:\n",
            "      Successfully uninstalled gensim-4.3.1\n",
            "Successfully installed gensim-3.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim==3.6.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYtwv5kFad9n"
      },
      "source": [
        "# Model Load"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANejsX2f2FNX",
        "outputId": "8d582948-dac5-4e37-e951-44ddd92ed62e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8O7hhm7CYfZR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy_Yxtd4YhFL",
        "outputId": "8ca2c8a1-4cc3-424b-dd2c-3a5c00314503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n",
            "/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"
          ]
        }
      ],
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7zGClwZ1XXr0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_UNJ6nbcYB-v"
      },
      "outputs": [],
      "source": [
        "fpath = 'drive/MyDrive/tripbuilder_data/TLD/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TxgfDoUWYL7j"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n",
        "        \n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=1202,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v6XU-XKYPvg",
        "outputId": "ed226ec8-4923-4e56-8dba-3f53cc7a96cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JmBb46BpYOE9"
      },
      "outputs": [],
      "source": [
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PyNnLxS6YD9h"
      },
      "outputs": [],
      "source": [
        "model = torch.load('drive/MyDrive/tripbuilder_modules/TRIFIT/BertClassifier_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOJX4AaIag68"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6pN11_nGcfIb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TJt1ychpe_yE"
      },
      "outputs": [],
      "source": [
        "fpath = 'drive/MyDrive/tripbuilder_data/TLD/'\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "data_use = pd.read_csv(fpath+'Data_for_Encoder.csv')\n",
        "encoder.fit(list(data_use['class']))\n",
        "\n",
        "encoded_words = encoder.transform(data_use[\"class\"])\n",
        "word_dict = dict(zip(range(len(encoder.classes_)), encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY_ZDkfIgnKt",
        "outputId": "a89587ad-19df-4fbb-8ef1-acf37010fdc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "#토큰화\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aZqEIh6XgrVI"
      },
      "outputs": [],
      "source": [
        "max_len = 30\n",
        "batch_size = 16\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Tsp-XcOEgYsQ"
      },
      "outputs": [],
      "source": [
        "def predict(predict_sentences):\n",
        "\n",
        "    data = [[predict_sentence, '0'] for predict_sentence in predict_sentences]\n",
        "    another_test = BERTDataset(data, 0, 1, tok, max_len, True, False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    result = []\n",
        "\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "        test_eval=[]\n",
        "        for logits in out:\n",
        "            logit = logits.detach().cpu().numpy()\n",
        "            res_label = encoder.inverse_transform([np.argmax(logit)])[0]\n",
        "            result.append(res_label)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "RqdfGOFrg8WT"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "nCDFkwgajra2",
        "outputId": "a5f3a15f-a39e-4957-9bcf-903ac836ccec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    name     id cate1  cate2        locX       locY  \\\n",
              "0    마곡장  SEO_0   음식점    음식점  126.829238  37.558123   \n",
              "1     더바  SEO_1   음식점    음식점  127.027916  37.493962   \n",
              "2  사이커피바  SEO_2    카페    음식점  127.033280  37.663038   \n",
              "3   종로맛집  SEO_3   음식점  육류,고기  126.994503  37.570158   \n",
              "4     하루  SEO_4   음식점    음식점  127.055578  37.507680   \n",
              "\n",
              "                                       address       callnum  time  restday  \\\n",
              "0  서울특별시 강서구 마곡중앙4로 22, 파인스퀘어 B동 1층 110호 (마곡동)          None   NaN      NaN   \n",
              "1        서울특별시 강남구 삼성로86길 11, 거봉INC 지하1층 (대치동)          None   NaN      NaN   \n",
              "2                 서울특별시 도봉구 도당로9길 22, 1층 (방학동)          None   NaN      NaN   \n",
              "3                서울특별시 종로구 통일로 156-3, 1층 (교남동)  02-2263-6658   NaN      NaN   \n",
              "4       서울특별시 강남구 언주로30길 57, 지하1층 (도곡동, 타워팰리스)   02-538-4555   NaN      NaN   \n",
              "\n",
              "                                            contents  imgs  tag  num_txt  \\\n",
              "0  [안녕하세요~! 경제적 자유를 위해 공부하고 행동하는 플랙비입니당!​이번에는 서울 ...   NaN  NaN    99375   \n",
              "1  [털삐예요❣​텍사스데브라질 갔다가 들르면 딱 좋은 거리압구정역에서 걸어서 7분정도 ...   NaN  NaN    99037   \n",
              "2  [ 도봉구 방학동에 위치한 동네카페 ‘사이커피바(Sighcoffeebar)’에 다녀...   NaN  NaN    98680   \n",
              "3  [​한 주의 절반이 지나갔네요!!이번 주말에는 뭐 드실 계획이신가용???저는 지난 ...   NaN  NaN    98945   \n",
              "4  [서울 강남구을 당원협의회에 방문했습니다.궂은 날씨에도 많은 당원 여러분이 모여주셨...   NaN  NaN    96690   \n",
              "\n",
              "   staytime  cong  \n",
              "0       NaN   NaN  \n",
              "1       NaN   NaN  \n",
              "2       NaN   NaN  \n",
              "3       NaN   NaN  \n",
              "4       NaN   NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c07c447-c388-495a-a639-2780182b5ce6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>id</th>\n",
              "      <th>cate1</th>\n",
              "      <th>cate2</th>\n",
              "      <th>locX</th>\n",
              "      <th>locY</th>\n",
              "      <th>address</th>\n",
              "      <th>callnum</th>\n",
              "      <th>time</th>\n",
              "      <th>restday</th>\n",
              "      <th>contents</th>\n",
              "      <th>imgs</th>\n",
              "      <th>tag</th>\n",
              "      <th>num_txt</th>\n",
              "      <th>staytime</th>\n",
              "      <th>cong</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>마곡장</td>\n",
              "      <td>SEO_0</td>\n",
              "      <td>음식점</td>\n",
              "      <td>음식점</td>\n",
              "      <td>126.829238</td>\n",
              "      <td>37.558123</td>\n",
              "      <td>서울특별시 강서구 마곡중앙4로 22, 파인스퀘어 B동 1층 110호 (마곡동)</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[안녕하세요~! 경제적 자유를 위해 공부하고 행동하는 플랙비입니당!​이번에는 서울 ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>99375</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>더바</td>\n",
              "      <td>SEO_1</td>\n",
              "      <td>음식점</td>\n",
              "      <td>음식점</td>\n",
              "      <td>127.027916</td>\n",
              "      <td>37.493962</td>\n",
              "      <td>서울특별시 강남구 삼성로86길 11, 거봉INC 지하1층 (대치동)</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[털삐예요❣​텍사스데브라질 갔다가 들르면 딱 좋은 거리압구정역에서 걸어서 7분정도 ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>99037</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>사이커피바</td>\n",
              "      <td>SEO_2</td>\n",
              "      <td>카페</td>\n",
              "      <td>음식점</td>\n",
              "      <td>127.033280</td>\n",
              "      <td>37.663038</td>\n",
              "      <td>서울특별시 도봉구 도당로9길 22, 1층 (방학동)</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[ 도봉구 방학동에 위치한 동네카페 ‘사이커피바(Sighcoffeebar)’에 다녀...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98680</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>종로맛집</td>\n",
              "      <td>SEO_3</td>\n",
              "      <td>음식점</td>\n",
              "      <td>육류,고기</td>\n",
              "      <td>126.994503</td>\n",
              "      <td>37.570158</td>\n",
              "      <td>서울특별시 종로구 통일로 156-3, 1층 (교남동)</td>\n",
              "      <td>02-2263-6658</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[​한 주의 절반이 지나갔네요!!이번 주말에는 뭐 드실 계획이신가용???저는 지난 ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>98945</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>하루</td>\n",
              "      <td>SEO_4</td>\n",
              "      <td>음식점</td>\n",
              "      <td>음식점</td>\n",
              "      <td>127.055578</td>\n",
              "      <td>37.507680</td>\n",
              "      <td>서울특별시 강남구 언주로30길 57, 지하1층 (도곡동, 타워팰리스)</td>\n",
              "      <td>02-538-4555</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[서울 강남구을 당원협의회에 방문했습니다.궂은 날씨에도 많은 당원 여러분이 모여주셨...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>96690</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c07c447-c388-495a-a639-2780182b5ce6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c07c447-c388-495a-a639-2780182b5ce6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c07c447-c388-495a-a639-2780182b5ce6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "fpath = 'drive/MyDrive/tripbuilder_data/PLA000/'\n",
        "data = pd.read_json(fpath+'Seoul_PLA000.json')\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "wXhuv3FHrv33"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def getTime(sec):\n",
        "  sec = int(sec)\n",
        "  h = sec//3600\n",
        "  m = (sec-h*3600)//60\n",
        "  s = (sec-h*3600)%60\n",
        "  return f\"{h}h {m}m {s}s\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "-LnPuvA6D3Ld"
      },
      "outputs": [],
      "source": [
        "data = data.iloc[5000:]\n",
        "data.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "eaX2VTO1r9-s"
      },
      "outputs": [],
      "source": [
        "cont_data = data[\"contents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "quzxZ_TG03ws"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def process(text):\n",
        "    text = re.sub(r'\\u200b', '.', text)\n",
        "    text = re.sub(r'[\\!\\~\\?\\^\\n\\/:]', '.', text)\n",
        "    text = re.sub(r'[\\u3131-\\u314E\\u314F-\\u3163]', '', text)\n",
        "    text = re.sub(r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF]', '', text)\n",
        "    text = re.sub(r'o', '', text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "YlHlT9dT4Pf6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"gensim.summarization.summarizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "q4rOWqw4rl0A",
        "outputId": "fed6194d-20ed-49f1-fb61-7b9f9cb821d6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport gensim.summarization as gs\\n\\nclass_lst = []\\n\\ns = time.time()\\nfor i in range(len(cont_data)):\\n  curr_cont = []\\n  for j in range(len(cont_data[i])):    \\n    sum_cont = gs.summarize(cont_data[i][j]+\". \"+\"안녕하세요. \"*5)\\n    for sent in sum_cont.split(\".\"):\\n      sent = process(sent)\\n      if len(sent)==0:\\n        continue\\n      sent = \"\".join(sent.split(\" \"))\\n      curr_cont.append(predict(sent))\\n      t = time.time()-s\\n    print(f\"\\r[{j+1}/{len(cont_data[i])}]|Completed...[{getTime(t/(j+1)*(len(cont_data[i])-j-1))}]Remain\",end=\"\")\\n  class_lst.append(curr_cont)\\n  break\\ne = time.time()\\nprint(f\"times:{e-s} sec\")\\nprint(len(curr_cont))\\n'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "import gensim.summarization as gs\n",
        "\n",
        "class_lst = []\n",
        "\n",
        "s = time.time()\n",
        "for i in range(len(cont_data)):\n",
        "  curr_cont = []\n",
        "  for j in range(len(cont_data[i])):    \n",
        "    sum_cont = gs.summarize(cont_data[i][j]+\". \"+\"안녕하세요. \"*5)\n",
        "    for sent in sum_cont.split(\".\"):\n",
        "      sent = process(sent)\n",
        "      if len(sent)==0:\n",
        "        continue\n",
        "      sent = \"\".join(sent.split(\" \"))\n",
        "      curr_cont.append(predict(sent))\n",
        "      t = time.time()-s\n",
        "    print(f\"\\r[{j+1}/{len(cont_data[i])}]|Completed...[{getTime(t/(j+1)*(len(cont_data[i])-j-1))}]Remain\",end=\"\")\n",
        "  class_lst.append(curr_cont)\n",
        "  break\n",
        "e = time.time()\n",
        "print(f\"times:{e-s} sec\")\n",
        "print(len(curr_cont))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.summarization as gs\n",
        "from IPython.display import clear_output\n",
        "\n",
        "spam_len = 9500; class_lst = []\n",
        "\n",
        "s = time.time()\n",
        "for i in range(len(cont_data)):\n",
        "  data_lst =  [\". \".join(process(cdata).split(\".\")) for cdata in cont_data[i] if len(cdata)<spam_len]\n",
        "  sum_lst = []\n",
        "\n",
        "  for j in range(0,len(data_lst),3):\n",
        "    try:\n",
        "      sum_cont = gs.summarize(\". \".join(data_lst[j:j+3]),ratio=0.1,split=True)\n",
        "      sum_lst+=sum_cont\n",
        "  \n",
        "    except:\n",
        "      pass\n",
        "  class_lst.append(predict(sum_lst))\n",
        "  t = time.time()-s\n",
        "  print(f\"\\r[{i+1}/{len(cont_data)}]|[{len(predict(sum_lst))}]Completed...[{getTime(t/(i+1)*(len(cont_data)-i-1))}]Remain\",end=\"\")\n",
        "\n",
        "  if i%100==99:\n",
        "    clear_output()\n",
        "\n",
        "e = time.time()\n",
        "print(f\"times:{e-s} sec\")\n",
        "\n",
        "fpath = 'drive/MyDrive/tripbuilder_data/PLA003/'\n",
        "\n",
        "data[\"tag\"] = class_lst\n",
        "data[['name', 'id', 'cate1', 'tag']].to_json(fpath+\"Seoul_PLA003_6.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYXbljWI4MUn",
        "outputId": "df4dd7f3-9477-4853-c586-6bbd02a9527e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18/984]|[74]Completed...[0h 28m 46s]Remain"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "WRJbTI_b9MSK",
        "outputId": "dbaae197-668a-4d86-fe89-958d155d53ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport gensim.summarization as gs\\nfrom IPython.display import clear_output\\n\\nclass_lst = []\\n\\ns = time.time()\\nfor i in range(len(cont_data)):\\n  curr_cont = []\\n  for j in range(len(cont_data[i])):    \\n    sum_cont = gs.summarize(cont_data[i][j]+\". \"+\"안녕하세요. \"*5,word_count=40)\\n    for sent in sum_cont.split(\".\"):\\n      sent = process(sent)\\n      if len(sent)==0:\\n        continue\\n      #sent = \" \".join(sent.split(\" \"))\\n      curr_cont.append(predict(sent))\\n      t = time.time()-s\\n  clear_output()\\n  print(f\"\\r[{i+1}/{len(cont_data)}]|Completed...[{getTime(t/(i+1)*(len(cont_data)-i-1))}]Remain\",end=\"\")\\n  class_lst.append(curr_cont)\\n\\ne = time.time()\\nprint(f\"times:{e-s} sec\")\\nprint(len(curr_cont))\\n\\nfpath = \\'drive/MyDrive/tripbuilder_data/PLA003/\\'\\n\\ndata[\"tag\"] = class_lst\\ndata[[\\'name\\', \\'id\\', \\'cate1\\', \\'tag\\']].to_json(fpath+\"Seoul_PLA003_1.json\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ],
      "source": [
        "\"\"\"\n",
        "import gensim.summarization as gs\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class_lst = []\n",
        "\n",
        "s = time.time()\n",
        "for i in range(len(cont_data)):\n",
        "  curr_cont = []\n",
        "  for j in range(len(cont_data[i])):    \n",
        "    sum_cont = gs.summarize(cont_data[i][j]+\". \"+\"안녕하세요. \"*5,word_count=40)\n",
        "    for sent in sum_cont.split(\".\"):\n",
        "      sent = process(sent)\n",
        "      if len(sent)==0:\n",
        "        continue\n",
        "      #sent = \" \".join(sent.split(\" \"))\n",
        "      curr_cont.append(predict(sent))\n",
        "      t = time.time()-s\n",
        "  clear_output()\n",
        "  print(f\"\\r[{i+1}/{len(cont_data)}]|Completed...[{getTime(t/(i+1)*(len(cont_data)-i-1))}]Remain\",end=\"\")\n",
        "  class_lst.append(curr_cont)\n",
        "\n",
        "e = time.time()\n",
        "print(f\"times:{e-s} sec\")\n",
        "print(len(curr_cont))\n",
        "\n",
        "fpath = 'drive/MyDrive/tripbuilder_data/PLA003/'\n",
        "\n",
        "data[\"tag\"] = class_lst\n",
        "data[['name', 'id', 'cate1', 'tag']].to_json(fpath+\"Seoul_PLA003_1.json\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Pguj3WDe-VKf",
        "outputId": "8e035e70-ee8b-43d2-bcca-89a5e0e4af5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Testing Code: 약 25초 소요(장소 1개, 글 40개 처리)\\nfor j in range(len(cont_data[i])):    \\n    sum_cont = gs.summarize(cont_data[i][j]+\". \"+\"안녕하세요. \"*5,word_count=40)\\n    for sent in sum_cont.split(\".\"):\\n      sent = process(sent)\\n      if len(sent)==0:\\n        continue\\n      sent = \" \".join(sent.split(\" \"))\\n      curr_cont.append(predict(sent))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "\"\"\"# Testing Code: 약 25초 소요(장소 1개, 글 40개 처리)\n",
        "for j in range(len(cont_data[i])):    \n",
        "    sum_cont = gs.summarize(cont_data[i][j]+\". \"+\"안녕하세요. \"*5,word_count=40)\n",
        "    for sent in sum_cont.split(\".\"):\n",
        "      sent = process(sent)\n",
        "      if len(sent)==0:\n",
        "        continue\n",
        "      sent = \" \".join(sent.split(\" \"))\n",
        "      curr_cont.append(predict(sent))\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Vd6GYlveaZ-q"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}